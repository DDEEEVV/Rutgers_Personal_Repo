{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Instructor Do: Terms Relevance (Understanding TF-IDF)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Initial imports\n","import nltk\n","from nltk.corpus import reuters\n","import numpy as np\n","import pandas as pd\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n"]},{"cell_type":"markdown","metadata":{},"source":["## Loading Text from the Reuters Dataset\n","\n","To demonstrate how TF-IDF works, we will use the _Reuters_ dataset that is bundled in NLTK."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package reuters to /Users/ddevii/nltk_data...\n","[nltk_data]   Package reuters is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Download/update the Reuters dataset\n","nltk.download(\"reuters\")\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of docs in the corpus: 10788\n"]}],"source":["# Count the total number of documents in the collection\n","doc_ids = reuters.fileids()\n","print(f\"Total number of docs in the corpus: {len(doc_ids)}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Getting Bag of Words from a Single Document\n","\n","We select a single document from the corpus to get it's \"Bag of Words\". The same can be done from multiple documents by pasing a list of documents (or documents ids on this example) to the `CountVectorizer()` object."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DUTCH ADJUSTED UNEMPLOYMENT RISES IN MARCH\n","  Dutch seasonally adjusted unemployment\n","  rose in the month to end-March to a total 693,000 from 690,600\n","  at end-February, but was well down from 730,100 at end-March\n","  1986, Social Affairs Ministry figures show.\n","      The figure for male jobless rose by 2,000 in the month to\n","  436,500 compared with 470,700 a year earlier. The figure for\n","  women was 256,500 at end-March against 256,100 a month earlier\n","  and 259,400 at end-March 1986.\n","      On an unadjusted basis total unemployment fell by 16,500 in\n","  the month to end-March to 692,200. In March 1986 the figure was\n","  725,000.\n","      A ministry spokesman said the unadjusted figures showed a\n","  smaller than usual seasonal decrease for the time of year,\n","  because of particularly cold weather delaying work in the\n","  building industry. He said this explained the increase in the\n","  adjusted statistics.\n","      Total vacancies available rose by 1,900 to 26,300 at\n","  end-March. A year earlier the figure was 28,763.\n","  \n","\n","\n"]}],"source":["# Select and print the original single document text\n","doc_id = \"test/15045\"\n","doc_text = reuters.raw(doc_id)\n","print(doc_text)\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['000', '100', '16', '1986', '200', '256', '259', '26', '28', '300', '400', '436', '470', '500', '600', '690', '692', '693', '700', '725', '730', '763', '900', 'adjusted', 'affairs', 'available', 'basis', 'building', 'cold', 'compared', 'decrease', 'delaying', 'dutch', 'earlier', 'end', 'explained', 'february', 'fell', 'figure', 'figures', 'increase', 'industry', 'jobless', 'male', 'march', 'ministry', 'month', 'particularly', 'rises', 'rose', 'said', 'seasonal', 'seasonally', 'showed', 'smaller', 'social', 'spokesman', 'statistics', 'time', 'total', 'unadjusted', 'unemployment', 'usual', 'vacancies', 'weather', 'women', 'work', 'year']\n"]},{"name":"stderr","output_type":"stream","text":["/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["# Creating the CountVectorizer instance defining the stopwords in English to be ignored\n","vectorizer = CountVectorizer(stop_words=\"english\")\n","\n","# Getting the tokenization and occurrence counting\n","X = vectorizer.fit_transform([doc_text])\n","\n","# Retrieve unique words list\n","words = vectorizer.get_feature_names()\n","print(words)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# X raw data contains the occurrence of each term in the document. A unique ID is assigned to each term.\n","print(X)\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Word</th>\n","      <th>Word_Count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>100</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>16</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1986</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>200</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>vacancies</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>weather</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>women</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>work</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>year</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>68 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["         Word  Word_Count\n","0         000           3\n","1         100           2\n","2          16           1\n","3        1986           3\n","4         200           1\n","..        ...         ...\n","63  vacancies           1\n","64    weather           1\n","65      women           1\n","66       work           1\n","67       year           3\n","\n","[68 rows x 2 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Getting the bag of words as DataFrame\n","words_df = pd.DataFrame(\n","    list(zip(words, np.ravel(X.sum(axis=0)))), columns=[\"Word\", \"Word_Count\"]\n",")\n","words_df\n"]},{"cell_type":"markdown","metadata":{},"source":["## Calculating the TF-IDF from a Corpus"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NICKEL PRICES UNLIKELY TO RISE MUCH - SHEARSON\n","  Nickel prices are unlikely to rise\n","  significantly from current levels unless further steps are\n","  taken to reduce production, Shearson Lehman Brothers said in\n","  its quarterly nickel market report.\n","      The market had recovered slightly to around 1.72 dlrs a lb\n","  yesterday from its four year low of 1.55 dlrs in early January,\n","  due to the absence of Soviet nickel cathode deliveries, but\n","  Shearson sees Soviet shipments soon returning to last year's\n","  buoyant levels, which should ease current tightness.\n","      Output reductions by producers will take effect later this\n","  year but are likely to be offset by increases elsewhere.\n","      Shearson said the nickel market will be virtually in\n","  balance during 1987, with total non-Socialist world demand at\n","  556,000 tonnes, compared with an estimated 544,000 tonnes in\n","  1986, production at 505,000 tonnes (504,000) and imports from\n","  Socialist countries at 47,000 tonnes (50,000).\n","      It forecast prices will edge higher during the year from a\n","  first quarter average of 1.67 dlrs a lb up to 1.77 dlrs in the\n","  last quarter. The year's average will be around 1.72 dlrs a lb\n","  compared with 1.76 dlrs in 1986, using London Metal Exchange\n","  cash metal prices in dollar terms and assuming an average 1987\n","  sterling exchange rate of 1.55 dlrs.\n","  \n","\n","\n"]}],"source":["# Getting the corpus (first 1000 files from Reuters dataset)\n","all_docs_id = reuters.fileids()\n","corpus_id = all_docs_id[0:1000]\n","corpus = [reuters.raw(doc) for doc in corpus_id]\n","\n","# Print sample document\n","print(corpus[50])\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Getting the TF-IDF\n","vectorizer = TfidfVectorizer(stop_words=\"english\")\n","X_corpus = vectorizer.fit_transform(corpus)\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Matrix shape: (1000, 9489)\n","Total number of documents: 1000\n","Total number of unique words (tokens): 9489\n"]}],"source":["# Getting matrix info\n","print(f\"Matrix shape: {X_corpus.shape}\")\n","print(f\"Total number of documents: {X_corpus.shape[0]}\")\n","print(f\"Total number of unique words (tokens): {X_corpus.shape[1]}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Retrieve words list from corpus\n","words_corpus = vectorizer.get_feature_names()\n","print(words_corpus)\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Getting the TF-IDF weight of each word in corpus as DataFrame\n","words_corpus_df = pd.DataFrame(\n","    list(zip(words_corpus, np.ravel(X_corpus.mean(axis=0)))), columns=[\"Word\", \"TF-IDF\"]\n",")\n","\n","words_corpus_df = words_corpus_df.sort_values(by=[\"TF-IDF\"], ascending=False)\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Word</th>\n","      <th>TF-IDF</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9199</th>\n","      <td>vs</td>\n","      <td>0.079701</td>\n","    </tr>\n","    <tr>\n","      <th>5885</th>\n","      <td>mln</td>\n","      <td>0.061460</td>\n","    </tr>\n","    <tr>\n","      <th>2971</th>\n","      <td>cts</td>\n","      <td>0.051221</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000</td>\n","      <td>0.047185</td>\n","    </tr>\n","    <tr>\n","      <th>7680</th>\n","      <td>said</td>\n","      <td>0.045466</td>\n","    </tr>\n","    <tr>\n","      <th>6083</th>\n","      <td>net</td>\n","      <td>0.038892</td>\n","    </tr>\n","    <tr>\n","      <th>3391</th>\n","      <td>dlrs</td>\n","      <td>0.038615</td>\n","    </tr>\n","    <tr>\n","      <th>6495</th>\n","      <td>pct</td>\n","      <td>0.028682</td>\n","    </tr>\n","    <tr>\n","      <th>7953</th>\n","      <td>shr</td>\n","      <td>0.027749</td>\n","    </tr>\n","    <tr>\n","      <th>5538</th>\n","      <td>lt</td>\n","      <td>0.027100</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Word    TF-IDF\n","9199    vs  0.079701\n","5885   mln  0.061460\n","2971   cts  0.051221\n","1      000  0.047185\n","7680  said  0.045466\n","6083   net  0.038892\n","3391  dlrs  0.038615\n","6495   pct  0.028682\n","7953   shr  0.027749\n","5538    lt  0.027100"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Highest 10 TF-IDF scores\n","words_corpus_df.head(10)\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Word</th>\n","      <th>TF-IDF</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3160</th>\n","      <td>denotes</td>\n","      <td>0.000005</td>\n","    </tr>\n","    <tr>\n","      <th>5906</th>\n","      <td>modification</td>\n","      <td>0.000005</td>\n","    </tr>\n","    <tr>\n","      <th>2144</th>\n","      <td>bulgur</td>\n","      <td>0.000005</td>\n","    </tr>\n","    <tr>\n","      <th>2914</th>\n","      <td>cracked</td>\n","      <td>0.000005</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>019</td>\n","      <td>0.000005</td>\n","    </tr>\n","    <tr>\n","      <th>402</th>\n","      <td>302</td>\n","      <td>0.000005</td>\n","    </tr>\n","    <tr>\n","      <th>1024</th>\n","      <td>893</td>\n","      <td>0.000005</td>\n","    </tr>\n","    <tr>\n","      <th>1053</th>\n","      <td>927</td>\n","      <td>0.000005</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>076</td>\n","      <td>0.000005</td>\n","    </tr>\n","    <tr>\n","      <th>7600</th>\n","      <td>rolled</td>\n","      <td>0.000005</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Word    TF-IDF\n","3160       denotes  0.000005\n","5906  modification  0.000005\n","2144        bulgur  0.000005\n","2914       cracked  0.000005\n","20             019  0.000005\n","402            302  0.000005\n","1024           893  0.000005\n","1053           927  0.000005\n","71             076  0.000005\n","7600        rolled  0.000005"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Lowest 10 TF-IDF scores\n","words_corpus_df.tail(10)\n"]}],"metadata":{"file_extension":".py","interpreter":{"hash":"4396f389b93e7269692bd3bea4c62813bbe379469bde939b058805f538feec11"},"kernelspec":{"display_name":"Python 3.7.7 ('dev')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","orig_nbformat":2,"pygments_lexer":"ipython3","version":3},"nbformat":4,"nbformat_minor":2}
